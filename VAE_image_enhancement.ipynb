{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sans-mishra/Underwater-Image-Enhancement-using-VAE-GAN-and-Diffusion/blob/main/VAE_image_enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "M1S0rop7fVqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfYk3R6-iizB",
        "outputId": "7fb78cb6-f4a8-4d26-d303-f5058cac017b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdyvXbpyORM5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, mean_squared_error as mse, structural_similarity as ssim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define transformations"
      ],
      "metadata": {
        "id": "3j8l9we7fx7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "jzi-opPxf4cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset class for loading images"
      ],
      "metadata": {
        "id": "EoGnAZhHgVvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnderwaterDataset(Dataset):\n",
        "    def __init__(self, raw_dir, reference_dir, transform=None):\n",
        "        self.raw_dir = raw_dir\n",
        "        self.reference_dir = reference_dir\n",
        "        self.transform = transform\n",
        "        self.raw_images = sorted(os.listdir(raw_dir))\n",
        "        self.reference_images = sorted(os.listdir(reference_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raw_path = os.path.join(self.raw_dir, self.raw_images[idx])\n",
        "        reference_path = os.path.join(self.reference_dir, self.reference_images[idx])\n",
        "\n",
        "        raw_image = Image.open(raw_path).convert(\"RGB\")\n",
        "        reference_image = Image.open(reference_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            raw_image = self.transform(raw_image)\n",
        "            reference_image = self.transform(reference_image)\n",
        "\n",
        "        return raw_image, reference_image"
      ],
      "metadata": {
        "id": "UjuQfmSKggUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the VAE architecture"
      ],
      "metadata": {
        "id": "PV2g0pQmgrB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size):\n",
        "        super(VAE, self).__init__()\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # Encoder\n",
        "        self.enc_conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.enc_conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.flattened_size = 128 * (image_size[1] // 4) * (image_size[2] // 4)\n",
        "        self.enc_fc1 = nn.Linear(self.flattened_size, 256)\n",
        "        self.enc_fc21 = nn.Linear(256, 256)  # Mu (mean)\n",
        "        self.enc_fc22 = nn.Linear(256, 256)  # Logvar (log variance)\n",
        "        self.dropout = nn.Dropout(0.2)  # Dropout layer\n",
        "\n",
        "        # Decoder\n",
        "        self.dec_fc1 = nn.Linear(256, 256)\n",
        "        self.dec_fc2 = nn.Linear(256, self.flattened_size)\n",
        "        self.dec_conv1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.dec_conv2 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = F.relu(self.enc_conv1(x))\n",
        "        x = F.relu(self.enc_conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.enc_fc1(x))\n",
        "        x = self.dropout(x)  # Apply dropout in the encoder\n",
        "        mu = self.enc_fc21(x)\n",
        "        logvar = self.enc_fc22(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(mu)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = F.relu(self.dec_fc1(z))\n",
        "        z = F.relu(self.dec_fc2(z))\n",
        "        z = z.view(-1, 128, self.image_size[1] // 4, self.image_size[2] // 4)\n",
        "        z = F.relu(self.dec_conv1(z))\n",
        "        z = torch.sigmoid(self.dec_conv2(z))\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "metadata": {
        "id": "otG1T0-Qgw96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function for VAE (reconstruction + KL divergence)"
      ],
      "metadata": {
        "id": "YnTJ2-s0g4zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='mean')\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
        "    return recon_loss + 0.01 * kl_loss  # Adjusted weight for KL divergence"
      ],
      "metadata": {
        "id": "6v64qcuCg8TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics for evaluation: PSNR, MSE, SSIM"
      ],
      "metadata": {
        "id": "OoG8cJl3hFxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(output, reference):\n",
        "    output_np = output.permute(1, 2, 0).cpu().numpy()  # Convert to HxWxC format\n",
        "    reference_np = reference.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # Ensure both images are in range [0, 1]\n",
        "    output_np = (output_np + 1) / 2  # Convert from [-1, 1] to [0, 1]\n",
        "    reference_np = (reference_np + 1) / 2\n",
        "\n",
        "    data_range=1.0\n",
        "    psnr_val = psnr(reference_np, output_np, data_range=data_range)\n",
        "    mse_val = mse(reference_np, output_np)\n",
        "    ssim_val = ssim(reference_np, output_np, multichannel=True, win_size=3, data_range=data_range)\n",
        "\n",
        "    return psnr_val, mse_val, ssim_val"
      ],
      "metadata": {
        "id": "Nf0j4MjShLOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function with dataset paths and training/testing loops"
      ],
      "metadata": {
        "id": "2zFbKvNFhQaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define dataset paths\n",
        "    train_raw_dir = '/content/drive/MyDrive/archive (2)/Train/Raw'\n",
        "    train_reference_dir = '/content/drive/MyDrive/archive (2)/Train/Reference'\n",
        "    test_raw_dir = '/content/drive/MyDrive/archive (2)/Test/Raw'\n",
        "    test_reference_dir = '/content/drive/MyDrive/archive (2)/Test/Reference'\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset = UnderwaterDataset(train_raw_dir, train_reference_dir, transform=transform)\n",
        "    test_dataset = UnderwaterDataset(test_raw_dir, test_reference_dir, transform=transform)\n",
        "\n",
        "    # DataLoader for batching\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    # Model, optimizer, and device setup\n",
        "    image_size = (3, 256, 256)\n",
        "    vae_model = VAE(image_size).to(device)\n",
        "    optimizer = optim.Adam(vae_model.parameters(), lr=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(30):  # Increased number of epochs\n",
        "        vae_model.train()\n",
        "        total_loss = 0\n",
        "        for raw, reference in train_loader:\n",
        "            raw, reference = raw.to(device), reference.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = vae_model(raw)\n",
        "            loss = vae_loss(recon_batch, reference, mu, logvar)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(vae_model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}')\n",
        "\n",
        "    # Evaluation\n",
        "    vae_model.eval()\n",
        "    psnr_scores, mse_scores, ssim_scores = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for raw, reference in test_loader:\n",
        "            raw, reference = raw.to(device), reference.to(device)\n",
        "            recon_batch, _, _ = vae_model(raw)\n",
        "            for i in range(raw.size(0)):\n",
        "                psnr_val, mse_val, ssim_val = compute_metrics(recon_batch[i], reference[i])\n",
        "                psnr_scores.append(psnr_val)\n",
        "                mse_scores.append(mse_val)\n",
        "                ssim_scores.append(ssim_val)\n",
        "\n",
        "    print(f'Average PSNR: {np.mean(psnr_scores):.4f}, Average MSE: {np.mean(mse_scores):.4f}, Average SSIM: {np.mean(ssim_scores):.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "wBxcebN0hUgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running function"
      ],
      "metadata": {
        "id": "cxeGUqlmkKRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyiRSLeckPSi",
        "outputId": "e8ad58ff-69ea-4ab1-d118-efd4530a5aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1, Loss: 0.5559\n",
            "Epoch 2, Loss: 0.3159\n",
            "Epoch 3, Loss: 0.2663\n",
            "Epoch 4, Loss: 0.2631\n",
            "Epoch 5, Loss: 0.2616\n",
            "Epoch 6, Loss: 0.2606\n",
            "Epoch 7, Loss: 0.2597\n",
            "Epoch 8, Loss: 0.2587\n",
            "Epoch 9, Loss: 0.2582\n",
            "Epoch 10, Loss: 0.2575\n",
            "Epoch 11, Loss: 0.2570\n",
            "Epoch 12, Loss: 0.2566\n",
            "Epoch 13, Loss: 0.2564\n",
            "Epoch 14, Loss: 0.2564\n",
            "Epoch 15, Loss: 0.2561\n",
            "Epoch 16, Loss: 0.2560\n",
            "Epoch 17, Loss: 0.2560\n",
            "Epoch 18, Loss: 0.2557\n",
            "Epoch 19, Loss: 0.2557\n",
            "Epoch 20, Loss: 0.2557\n",
            "Epoch 21, Loss: 0.2558\n",
            "Epoch 22, Loss: 0.2554\n",
            "Epoch 23, Loss: 0.2555\n",
            "Epoch 24, Loss: 0.2553\n",
            "Epoch 25, Loss: 0.2554\n",
            "Epoch 26, Loss: 0.2555\n",
            "Epoch 27, Loss: 0.2555\n",
            "Epoch 28, Loss: 0.2555\n",
            "Epoch 29, Loss: 0.2555\n",
            "Epoch 30, Loss: 0.2554\n",
            "Average PSNR: 12.1438, Average MSE: 0.0650, Average SSIM: 0.1592\n"
          ]
        }
      ]
    }
  ]
}